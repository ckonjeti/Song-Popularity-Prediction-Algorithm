{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import spotipy\n",
    "import billboard\n",
    "\n",
    "#import applemusicpy\n",
    "import lyricsgenius\n",
    "#import SpotifyCharts as sCharts\n",
    "import csv\n",
    "import os\n",
    "from textstat.textstat import textstat\n",
    "import threading as thread\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "from sklearn import linear_model, mixture\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/Chaitu Konjeti/SongPopularityPredictionAlgorithm/output\"\n",
    "genius = lyricsgenius.Genius(\"Xf0XfBJTZon0Sra2rGV56TAXp6jOUaLJVhmHxqbTW5mp-j6S2NVcmHWSLQ29v0dk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(path)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeSongCharacteristics(i, billboardChart, songs):\n",
    "    key = str(billboardChart[i].title + billboardChart[i].artist)\n",
    "\n",
    "    if key not in songs:\n",
    "        song = billboardChart[i]\n",
    "        title = billboardChart[i].title\n",
    "        artist = song.artist\n",
    "        peakpos = song.peakPos\n",
    "        lastpos = song.lastPos\n",
    "        numWeeks = song.weeks\n",
    "        currentPos = song.rank\n",
    "        isNew = song.isNew\n",
    "        lyrics = genius.search_song(title, artist).lyrics\n",
    "        row = [title, artist, lyrics, peakpos, lastpos, numWeeks, currentPos, isNew]\n",
    "        songs[key] = row\n",
    "\n",
    "    if key in songs:\n",
    "        if billboardChart[i].peakPos != songs.get(key)[3]:\n",
    "            newRow = songs.get(key)\n",
    "            newRow[3] = billboardChart[i].peakPos\n",
    "            songs[key] = newRow\n",
    "        if billboardChart[i].weeks != songs.get(key)[5]:\n",
    "            newRow = songs.get(key)\n",
    "            newRow[5] = billboardChart[i].weeks\n",
    "            songs[key] = newRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllSongData(startMonth, startYear, endMonth, endYear, numSongs):\n",
    "    for year in range(startYear, endYear + 1):\n",
    "        thread.Thread(None, target=yearlySongData, args=(year, startMonth, endMonth, numSongs)).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yearlySongData(year, startMonth, endMonth, numSongs):\n",
    "    for month in range (startMonth, endMonth + 1):\n",
    "            thread.Thread(None, target=monthlySongData, args=(year, month, numSongs)).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthlySongData(year, month, numSongs):\n",
    "        outputFileName = \"C:/Users/Chaitu Konjeti/SongPopularityPredictionAlgorithm/output/billboardHot100_Lyrics_{}_{}.csv\".format(year, month)\n",
    "\n",
    "        with open(outputFileName, 'a+', newline='', encoding='utf-8') as outputFile:\n",
    "            songs = {}\n",
    "            day = 1\n",
    "            dataWriter = csv.writer(outputFile)\n",
    "\n",
    "            while (day <= 31):\n",
    "                if month in range(1, 10):\n",
    "                    try:\n",
    "                        billboardChart = billboard.ChartData('hot-100', date = \"{}-{:02d}-{}\".format(year, month, day))\n",
    "                        for i in range(0, numSongs):\n",
    "                            try:\n",
    "                                writeSongCharacteristics(i, billboardChart, songs)\n",
    "                            except:\n",
    "                                pass\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                elif month in range(10, 13):\n",
    "                    try:\n",
    "                        billboardChart = billboard.ChartData('hot-100', date = \"{}-{}-{}\".format(year, month, day))\n",
    "                        for i in range(0, numSongs):\n",
    "                            try:\n",
    "                                writeSongCharacteristics(i, billboardChart, songs)\n",
    "                            except:\n",
    "                                pass\n",
    "                    except:\n",
    "                        pass\n",
    "                day += 5\n",
    "\n",
    "            for key in songs:\n",
    "                if (len(songs[key][2]) < 10000):\n",
    "                    dataWriter.writerow(songs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyric_preprocessing(dir):\n",
    "    for filename in os.listdir(dir):\n",
    "        data = []\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        with open(dir + filename, encoding='utf-8', mode='r+') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            for row in csv_reader:\n",
    "                temp = row\n",
    "                num_positive = 0\n",
    "                num_negative = 0\n",
    "                num_neutral = 0\n",
    "                dale_chall_score = 0\n",
    "                #print(row[0])\n",
    "                lyrics = row[2]\n",
    "                lyrics = re.sub(r'[\\(\\[].*?[\\)\\]]', '', lyrics)\n",
    "                lyrics = os.linesep.join([s for s in lyrics.splitlines() if s])\n",
    "                #print(lyrics)\n",
    "                #this_sentence = lyrics.decode('utf-8')\n",
    "                #numlines = 0\n",
    "                for line in lyrics.splitlines():\n",
    "                    #print(line)\n",
    "                    comp = sid.polarity_scores(line)\n",
    "                    #print(comp)\n",
    "                    comp = comp['compound']\n",
    "                    if comp >= 0.5:\n",
    "                        num_positive += 1\n",
    "                    elif comp > -0.5 and comp < 0.5:\n",
    "                        num_neutral += 1\n",
    "                    else:\n",
    "                        num_negative += 1\n",
    "\n",
    "                    #numlines += 1\n",
    "\n",
    "                temp.append(num_positive)\n",
    "                temp.append(num_neutral)\n",
    "                temp.append(num_negative)\n",
    "                temp.append(textstat.dale_chall_readability_score(lyrics))\n",
    "                temp.append(textstat.difficult_words(lyrics))\n",
    "                data.append(temp)\n",
    "                #print(temp)\n",
    "            outputFileName = \"C:/Users/Chaitu Konjeti/song-popularity-prediction-algorithm/processed/\" + filename\n",
    "\n",
    "            with open(outputFileName, 'a+', newline='', encoding='utf-8') as outputFile:\n",
    "                dataWriter = csv.writer(outputFile)\n",
    "                for items in data:\n",
    "                    #print(items)\n",
    "                    dataWriter.writerow(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getAllSongData(1, 2000, 12, 2019, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_preprocessing(\"output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'C:/Users/Chaitu Konjeti/song-popularity-prediction-algorithm/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(dir):\n",
    "    with open(dir + filename, encoding='utf-8-sig', mode='r') as csv_file:\n",
    "        df = pd.read_csv(dir + filename, header = None)\n",
    "        #print(df.head())\n",
    "        df.columns = ['title', 'artist', 'lyrics', 'peakpos', 'lastpos', 'numWeeks', 'currentPos', 'isNew', 'pos', 'neu', 'neg', 'dale', 'diff']\n",
    "        # #print(df['title'])\n",
    "        # features = list(df.columns.values)\n",
    "        # features.remove('title')\n",
    "        # features.remove('artist')\n",
    "        # features.remove('currentPos')\n",
    "        # features.remove('lyrics')\n",
    "        # X.append(df[features])\n",
    "        # y.append(df['currentPos'])\n",
    "        for lyric in df['lyrics']:\n",
    "            X.append(lyric)\n",
    "        for pos in df['currentPos']:\n",
    "            y.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3))\n",
    "X = count_vectorizer.fit_transform(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chaitu Konjeti\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Chaitu Konjeti\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=1,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(verbose=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, 97, 29, 52, 29, 16, 97,  8, 97, 97, 99, 47, 97, 52, 97, 67, 97,\n",
       "       33, 97, 52, 67, 97, 99, 82, 26, 10, 85])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([43, 37, 94,  6, 66, 98, 57, 18, 54, 83, 70, 79, 45, 60, 90, 62, 34,\n",
       "       79, 31, 17, 49, 93, 46, 32,  5, 40, 78])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
